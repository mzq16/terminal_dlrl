{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import time\n",
    "import stable_baselines3 as sb3\n",
    "from stable_baselines3 import DQN\n",
    "import gymnasium as gym\n",
    "import gym_ENV\n",
    "import gym_ENV.envs\n",
    "from gymnasium.utils.env_checker import check_env\n",
    "from stable_baselines3.common.logger import configure\n",
    "from gym_ENV.envs import utils\n",
    "import time\n",
    "import pygame\n",
    "import tqdm\n",
    "from dqn.my_dqn import my_dqn\n",
    "\n",
    "\n",
    "def env_make(env_base):\n",
    "   pass\n",
    "\n",
    "env_base = gym.make('Terminal_Env-v0', num_vehicle = 10, map_size = [1200, 700], \n",
    "                    render_mode = 'rgb_array', seed = 24, text_width = 400,\n",
    "                    model_arg = {'input_dim': 2, 'hidden_dim': 64, 'output_dim': 2, 'num_layers': 2,},\n",
    "                 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5025, 0.4975])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = nn.Softmax(dim=0)\n",
    "t = torch.tensor([-0.38,-0.39])\n",
    "s(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omnisky/anaconda3/envs/py_mzq/lib/python3.8/site-packages/gymnasium/utils/passive_env_checker.py:159: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n"
     ]
    }
   ],
   "source": [
    "env=env_base\n",
    "obs, info = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omnisky/anaconda3/envs/py_mzq/lib/python3.8/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.get_render_img to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_render_img` for environment variables or `env.get_wrapper_attr('get_render_img')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "env.ev_handle._current_id = 141\n",
    "arr = env.get_render_img()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('dd.jpg', arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./tmp/sb3_log/\n"
     ]
    }
   ],
   "source": [
    "tmp_path = \"./tmp/sb3_log/\"\n",
    "# set up logger\n",
    "new_logger = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym_ENV.wandb.wandb_base import init_callback_list\n",
    "callback_list = init_callback_list(env = env_base, save_freq = 5e3, save_replay_buffer=True, verbose=2, wandb_flag=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = my_dqn(\"MultiInputPolicy\", env_base, verbose=0, buffer_size=10000, learning_starts=1000, train_freq=(10,'step'), gradient_steps=10)\n",
    "from dqn.my_dqn import my_dqn\n",
    "from dqn.my_policy import myPolicy\n",
    "model = my_dqn(myPolicy, env_base, verbose=0, buffer_size=10000, learning_starts=1000, train_freq=(10,'step'), gradient_steps=10,\n",
    "               target_update_interval=100, batch_size=256)\n",
    "\n",
    "model.set_logger(new_logger)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "myPolicy(\n",
       "  (q_net): myQNetwork(\n",
       "    (features_extractor): myExtractor(\n",
       "      (extractors): ModuleDict(\n",
       "        (des_id): Sequential(\n",
       "          (0): Flatten(start_dim=1, end_dim=-1)\n",
       "          (1): Linear(in_features=1, out_features=4, bias=True)\n",
       "          (2): ReLU()\n",
       "          (3): Linear(in_features=4, out_features=8, bias=True)\n",
       "          (4): ReLU()\n",
       "          (5): Linear(in_features=8, out_features=4, bias=True)\n",
       "          (6): ReLU()\n",
       "        )\n",
       "        (history_action): Sequential(\n",
       "          (0): Flatten(start_dim=1, end_dim=-1)\n",
       "          (1): Linear(in_features=5, out_features=16, bias=True)\n",
       "          (2): Linear(in_features=16, out_features=16, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (ov_id): Sequential(\n",
       "          (0): Flatten(start_dim=1, end_dim=-1)\n",
       "          (1): Linear(in_features=10, out_features=16, bias=True)\n",
       "          (2): Linear(in_features=16, out_features=16, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (render_img): NatureCNN(\n",
       "          (cnn): Sequential(\n",
       "            (0): Conv2d(3, 32, kernel_size=(8, 8), stride=(4, 4))\n",
       "            (1): ReLU()\n",
       "            (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
       "            (3): ReLU()\n",
       "            (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "            (5): ReLU()\n",
       "            (6): Flatten(start_dim=1, end_dim=-1)\n",
       "          )\n",
       "          (linear): Sequential(\n",
       "            (0): Linear(in_features=784896, out_features=1024, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (3): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (routes): Sequential(\n",
       "          (0): Flatten(start_dim=1, end_dim=-1)\n",
       "          (1): Linear(in_features=5, out_features=16, bias=True)\n",
       "          (2): Linear(in_features=16, out_features=16, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (q_net): Sequential(\n",
       "      (0): Linear(in_features=308, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=64, out_features=4, bias=True)\n",
       "    )\n",
       "    (softmax): Softmax(dim=1)\n",
       "  )\n",
       "  (q_net_target): myQNetwork(\n",
       "    (features_extractor): myExtractor(\n",
       "      (extractors): ModuleDict(\n",
       "        (des_id): Sequential(\n",
       "          (0): Flatten(start_dim=1, end_dim=-1)\n",
       "          (1): Linear(in_features=1, out_features=4, bias=True)\n",
       "          (2): ReLU()\n",
       "          (3): Linear(in_features=4, out_features=8, bias=True)\n",
       "          (4): ReLU()\n",
       "          (5): Linear(in_features=8, out_features=4, bias=True)\n",
       "          (6): ReLU()\n",
       "        )\n",
       "        (history_action): Sequential(\n",
       "          (0): Flatten(start_dim=1, end_dim=-1)\n",
       "          (1): Linear(in_features=5, out_features=16, bias=True)\n",
       "          (2): Linear(in_features=16, out_features=16, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (ov_id): Sequential(\n",
       "          (0): Flatten(start_dim=1, end_dim=-1)\n",
       "          (1): Linear(in_features=10, out_features=16, bias=True)\n",
       "          (2): Linear(in_features=16, out_features=16, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (render_img): NatureCNN(\n",
       "          (cnn): Sequential(\n",
       "            (0): Conv2d(3, 32, kernel_size=(8, 8), stride=(4, 4))\n",
       "            (1): ReLU()\n",
       "            (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
       "            (3): ReLU()\n",
       "            (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "            (5): ReLU()\n",
       "            (6): Flatten(start_dim=1, end_dim=-1)\n",
       "          )\n",
       "          (linear): Sequential(\n",
       "            (0): Linear(in_features=784896, out_features=1024, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (3): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (routes): Sequential(\n",
       "          (0): Flatten(start_dim=1, end_dim=-1)\n",
       "          (1): Linear(in_features=5, out_features=16, bias=True)\n",
       "          (2): Linear(in_features=16, out_features=16, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (q_net): Sequential(\n",
       "      (0): Linear(in_features=308, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=64, out_features=4, bias=True)\n",
       "    )\n",
       "    (softmax): Softmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.learn(total_timesteps=5e6, log_interval=50000, progress_bar=True, callback=callback_list, reset_num_timesteps=False, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_path = \"data/checkpoint_noimg/rl_model_replay_buffer_635000_steps.pkl\"\n",
    "model.load_replay_buffer(buffer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = \"data/checkpoint_noimg/rl_model_635000_steps.zip\"\n",
    "model = model.load(ckpt_path, env=env_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import tensor\n",
    "tt = tensor([[1.8429e-10, 1.0000e+00, 0.0000e+00, 0.0000e+00]], device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttt = tt.cpu().detach().numpy()\n",
    "\n",
    "ttt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[140, 144, 156, 224]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = env_base.unwrapped.G\n",
    "current_id = 141\n",
    "neighbour_ids = list(G.neighbors(current_id))\n",
    "neighbour_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = 'data/checkpoint/rl_model_90_steps.zip'\n",
    "new_model = model.load(ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.num_timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.logger.name_to_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.ep_info_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.ep_success_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym \n",
    "isinstance(env_base.observation_space, gym.spaces.Dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(env_base.observation_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs, info = env_base.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in obs.items():\n",
    "    print(type(v), v.dtype, type(obs_[k]), obs_[k].dtype)\n",
    "    print(v.shape, obs_[k].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs[0]['render_img'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_ = env_base.observation_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    h = env_base.step(0)\n",
    "    cv2.imwrite(f'd___{i}.jpg', h[0]['render_img'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h[0]['render_img'].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('d1.jpg', obs[0]['render_img'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('d.jpg', hh[0]['render_img'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "cv2.imwrite('dd.jpg',f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_mzq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
